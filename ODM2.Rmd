---
title: "ODM2"
author: "Amardeep Singh"
date: "June 3, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
library(tensorflow)
datasets <- tf$contrib$learn$datasets
mnist <- datasets$mnist$read_data_sets("MNIST-data", one_hot = TRUE)
```
```{r}
library(tensorflow)
x <- tf$placeholder(tf$float32, shape(NULL, 784L))
W <- tf$Variable(tf$zeros(shape(784L, 5L)))
b <- tf$Variable(tf$zeros(shape(5L)))
y <- tf$nn$softmax(tf$matmul(x, W) + b)
y_ <- tf$placeholder(tf$float32, shape(NULL,5L))
```
```{r}
cross_entropy <- tf$reduce_mean(-tf$reduce_sum(y_* tf$log(y), reduction_indices=1L))
optimizer <- tf$train$GradientDescentOptimizer(0.5)
train_step <- optimizer$minimize(cross_entropy)
init <- tf$global_variables_initializer()
sess <- tf$Session()
sess$run(init)
for (i in 1:1000) {
  batches <- mnist$train$next_batch(500L)
  batch_xs <- batches[[1]]
  batch_ys <- batches[[2]]
  sess$run(train_step,
           feed_dict = dict(x = batch_xs, y_ = batch_ys))
}
```
```{r}
correct_prediction <- tf$equal(tf$argmax(y, 1L), tf$argmax(y_, 1L))
accuracy <- tf$reduce_mean(tf$cast(correct_prediction, tf$float32))
sess$run(accuracy, feed_dict=dict(x = mnist$test$images, y_ = mnist$test$labels))

```
```{r}
library(keras)
install.packages("EBImage")
```
```{r}
source("http://bioconductor.org/biocLite.R")
biocLite("EBImage")
```
```{r}
library(EBImage)
```
```{r}
install.packages("pbapply")
```
```{r}
secondCat <- readImage("C:\\Users\\Amardeep\\Desktop\\INTERNSHIP\\data\\JPEGImages\\000020.jpg")
display(secondCat)
```
```{r}
# Set image size
width <- 50
height <- 50
 
extract_feature <- function(dir_path, width, height, labelsExist = T) {
img_size <- width * height
 
## List images in path
images_names <- list.files("C:\\Users\\Amardeep\\Desktop\\INTERNSHIP\\data\\JPEGImages")
 
if(labelsExist){
## Select only cats or dogs images
catdog <- str_extract(images_names, "^(cat|dog)")
# Set cat == 0 and dog == 1
key <- c("car" = 0, "person" = 1)
y <- key[catdog]
}
 
print(paste("Start processing", length(images_names), "images"))
## This function will resize an image, turn it into greyscale
feature_list <- pblapply(images_names, function(imgname) {
## Read image
img <- readImage(file.path(dir_path, imgname))
## Resize image
img_resized <- resize(img, w = width, h = height)
## Set to grayscale (normalized to max)
grayimg <- channel(img_resized, "gray")
## Get the image as a matrix
img_matrix <- grayimg@.Data
## Coerce to a vector (row-wise)
img_vector <- as.vector(t(img_matrix))
return(img_vector)
})
## bind the list of vector into matrix
feature_matrix <- do.call(rbind, feature_list)
feature_matrix <- as.data.frame(feature_matrix)
## Set names
names(feature_matrix) <- paste0("pixel", c(1:img_size))
 
if(labelsExist){
return(list(X = feature_matrix, y = y))
}else{
return(feature_matrix)
}
}

```
## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
x<-c(5:10,var=0.5)
```
```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
